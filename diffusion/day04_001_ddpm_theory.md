# Day 4 - Part 1: Denoising Diffusion Probabilistic Models (DDPM) Theory

## üìö Learning Objectives
By the end of this section, you will understand:
- Mathematical foundations of DDPM and its probabilistic formulation
- Theoretical analysis of forward and reverse diffusion processes
- Mathematical principles of variational lower bound (VLB) optimization
- Information-theoretic perspectives on noise scheduling and training objectives
- Theoretical frameworks for reparameterization tricks and loss simplification
- Mathematical modeling of DDPM vs score-based equivalence

---

## üéØ DDPM Mathematical Framework

### Probabilistic Formulation

#### Forward Diffusion Process
**Mathematical Definition**:
```
Markov Chain Formulation:
q(x‚ÇÅ:T | x‚ÇÄ) = ‚àè·µó‚Çå‚ÇÅ·µÄ q(x‚Çú | x‚Çú‚Çã‚ÇÅ)

Forward Transition:
q(x‚Çú | x‚Çú‚Çã‚ÇÅ) = N(x‚Çú; ‚àö(1-Œ≤‚Çú)x‚Çú‚Çã‚ÇÅ, Œ≤‚ÇúI)
where Œ≤‚Çú ‚àà (0,1) is noise schedule

Reparameterization:
x‚Çú = ‚àö(1-Œ≤‚Çú)x‚Çú‚Çã‚ÇÅ + ‚àöŒ≤‚Çú Œµ‚Çú
where Œµ‚Çú ~ N(0,I)

Cumulative Product:
Œ±‚Çú = 1 - Œ≤‚Çú
·æ±‚Çú = ‚àè‚Çõ‚Çå‚ÇÅ·µó Œ±‚Çõ

Direct Sampling:
q(x‚Çú | x‚ÇÄ) = N(x‚Çú; ‚àö·æ±‚Çú x‚ÇÄ, (1-·æ±‚Çú)I)
Closed-form sampling at any timestep
```

**Information-Theoretic Analysis**:
```
Mutual Information Decay:
I(x‚ÇÄ; x‚Çú) = H(x‚ÇÄ) - H(x‚ÇÄ|x‚Çú)
Decreases monotonically with t
Rate controlled by noise schedule Œ≤‚Çú

Signal-to-Noise Ratio:
SNR(t) = ·æ±‚Çú/(1-·æ±‚Çú)
Measures information preservation
High SNR: structure preserved
Low SNR: approaching pure noise

Entropy Evolution:
H(x‚Çú) increases with t
Differential entropy for continuous distributions
Final entropy H(x‚Çú) ‚âà H(N(0,I)) for large T

KL Divergence to Prior:
KL(q(x‚Çú|x‚ÇÄ) || p(x‚Çú)) ‚Üí 0 as T ‚Üí ‚àû
Forward process approaches chosen prior
Typically p(x‚Çú) = N(0,I)
```

#### Reverse Diffusion Process
**Mathematical Formulation**:
```
Reverse Markov Chain:
p_Œ∏(x‚ÇÄ:T) = p(x‚Çú) ‚àè·µó‚Çå‚ÇÅ·µÄ p_Œ∏(x‚Çú‚Çã‚ÇÅ | x‚Çú)

Reverse Transition:
p_Œ∏(x‚Çú‚Çã‚ÇÅ | x‚Çú) = N(x‚Çú‚Çã‚ÇÅ; Œº_Œ∏(x‚Çú,t), Œ£_Œ∏(x‚Çú,t))
Parameterized by neural network

Gaussian Assumption:
Reverse transitions are Gaussian
Motivated by forward process properties
Tractable for small step sizes

Mean Parameterization:
Œº_Œ∏(x‚Çú,t) = (1/‚àöŒ±‚Çú)(x‚Çú - (Œ≤‚Çú/‚àö(1-·æ±‚Çú))Œµ_Œ∏(x‚Çú,t))
Predict noise Œµ_Œ∏ instead of mean directly
Equivalent parameterizations available

Variance Schedule:
Œ£_Œ∏(x‚Çú,t) = œÉ‚Çú¬≤I
Can be learned or fixed
Common choice: œÉ‚Çú¬≤ = Œ≤‚Çú or œÉ‚Çú¬≤ = Œ≤ÃÉ‚Çú = (1-·æ±‚Çú‚Çã‚ÇÅ)/(1-·æ±‚Çú) Œ≤‚Çú
```

### Variational Lower Bound

#### Mathematical Derivation
**Evidence Lower Bound (ELBO)**:
```
Log-Likelihood Bound:
log p_Œ∏(x‚ÇÄ) ‚â• E_q[-log q(x‚ÇÅ:T|x‚ÇÄ) + log p_Œ∏(x‚ÇÄ:T)]

ELBO Decomposition:
L = E_q[log p_Œ∏(x‚ÇÄ|x‚ÇÅ) - KL(q(x‚Çú|x‚ÇÄ) || p(x‚Çú)) 
    - Œ£·µó‚Çå‚ÇÇ·µÄ KL(q(x‚Çú‚Çã‚ÇÅ|x‚Çú,x‚ÇÄ) || p_Œ∏(x‚Çú‚Çã‚ÇÅ|x‚Çú))]

Term Interpretation:
L‚ÇÄ: Reconstruction term
L‚Çú: Transition matching terms (t = 1,...,T-1)
L‚Çú: Prior matching term

Negative ELBO:
L = L‚ÇÄ + L‚ÇÅ + ... + L‚Çú‚Çã‚ÇÅ + L‚Çú
Minimize negative ELBO for training
```

**Simplified Loss Derivation**:
```
Posterior Distribution:
q(x‚Çú‚Çã‚ÇÅ|x‚Çú,x‚ÇÄ) = N(x‚Çú‚Çã‚ÇÅ; ŒºÃÉ‚Çú(x‚Çú,x‚ÇÄ), Œ≤ÃÉ‚ÇúI)
where ŒºÃÉ‚Çú(x‚Çú,x‚ÇÄ) = (‚àö·æ±‚Çú‚Çã‚ÇÅŒ≤‚Çúx‚ÇÄ + ‚àöŒ±‚Çú(1-·æ±‚Çú‚Çã‚ÇÅ)x‚Çú)/(1-·æ±‚Çú)

KL Divergence:
KL(q(x‚Çú‚Çã‚ÇÅ|x‚Çú,x‚ÇÄ) || p_Œ∏(x‚Çú‚Çã‚ÇÅ|x‚Çú)) = ¬ΩœÉ‚Çú¬≤||ŒºÃÉ‚Çú - Œº_Œ∏||¬≤

Reparameterization:
x‚Çú = ‚àö·æ±‚Çú x‚ÇÄ + ‚àö(1-·æ±‚Çú) Œµ
where Œµ ~ N(0,I)

Simplified Objective:
L_simple = E_t,x‚ÇÄ,Œµ[||Œµ - Œµ_Œ∏(x‚Çú,t)||¬≤]
Predict noise instead of mean
Equivalent to weighted VLB under certain conditions
```

#### Theoretical Analysis
**Optimality and Consistency**:
```
VLB Tightness:
Gap between log p_Œ∏(x‚ÇÄ) and ELBO
Depends on approximation quality of q(x‚ÇÅ:T|x‚ÇÄ)
Forward process design affects tightness

Asymptotic Behavior:
As T ‚Üí ‚àû and Œ≤‚Çú ‚Üí 0:
Forward process approaches SDE
Reverse process approaches score-based sampling
DDPM converges to score-based models

Optimal Reverse Process:
p*(x‚Çú‚Çã‚ÇÅ|x‚Çú) ‚àù q(x‚Çú|x‚Çú‚Çã‚ÇÅ)p*(x‚Çú‚Çã‚ÇÅ)
Bayes' theorem gives optimal reverse
Neural network approximates this optimal process

Parameterization Equivalence:
Different parameterizations (Œµ, Œº, x‚ÇÄ) equivalent
Choice affects optimization and numerical stability
Noise prediction often most stable
```

### Noise Schedule Analysis

#### Mathematical Principles
**Schedule Design Criteria**:
```
Coverage Requirement:
Œ≤‚Çú chosen to ensure q(x‚Çú|x‚ÇÄ) ‚âà N(0,I) for large T
Sufficient noise to erase structure

Information Preservation:
Balance between noise addition and structure retention
Too fast: information lost too quickly
Too slow: insufficient exploration at end

Mathematical Constraints:
0 < Œ≤‚Çú < 1 for all t
Monotonicity: often Œ≤‚Çú ‚â§ Œ≤‚Çú‚Çä‚ÇÅ
Boundary conditions: Œ≤‚ÇÅ small, Œ≤‚Çú moderate
```

**Common Schedules**:
```
Linear Schedule:
Œ≤‚Çú = Œ≤‚ÇÅ + (Œ≤‚Çú - Œ≤‚ÇÅ)(t-1)/(T-1)
Simple and interpretable
May not be optimal for all data types

Cosine Schedule:
Œ±‚Çú = cos¬≤((t/T + s)/(1 + s) √ó œÄ/2)
where s is small offset
Slower noise addition initially
Better preservation of coarse structure

Learned Schedules:
Optimize noise schedule parameters
Data-dependent adaptation
Computational overhead vs performance gain

Theoretical Optimality:
No universally optimal schedule
Depends on data distribution characteristics
Information-theoretic criteria for design
```

#### Signal-to-Noise Analysis
**SNR Evolution**:
```
SNR Definition:
SNR(t) = ·æ±‚Çú/(1-·æ±‚Çú) = E[||‚àö·æ±‚Çú x‚ÇÄ||¬≤]/E[||(1-·æ±‚Çú)Œµ||¬≤]

Log-SNR Parameterization:
log SNR(t) = log ·æ±‚Çú - log(1-·æ±‚Çú)
More stable for optimization
Linear in log-space often better

SNR-Based Schedules:
Choose log SNR(t) function directly
Convert to Œ≤‚Çú via relationship
More principled than direct Œ≤‚Çú specification

Critical SNR Values:
High SNR (> 1): structure dominates
Medium SNR (‚âà 1): balanced signal/noise
Low SNR (< 1): noise dominates
Transition points affect generation quality
```

### Connection to Score-Based Models

#### Mathematical Equivalence
**Score Function Connection**:
```
DDPM Score Relation:
Œµ_Œ∏(x‚Çú,t) = -‚àö(1-·æ±‚Çú) s_Œ∏(x‚Çú,t)
where s_Œ∏(x‚Çú,t) = ‚àálog p(x‚Çú)

Reverse Process Mean:
Œº_Œ∏(x‚Çú,t) = (1/‚àöŒ±‚Çú)(x‚Çú - (Œ≤‚Çú/‚àö(1-·æ±‚Çú))Œµ_Œ∏(x‚Çú,t))
= (1/‚àöŒ±‚Çú)(x‚Çú + Œ≤‚Çús_Œ∏(x‚Çú,t))

Langevin Connection:
DDPM reverse step ‚âà Langevin MCMC step
x‚Çú‚Çã‚ÇÅ = x‚Çú + ¬ΩŒ≤‚Çús_Œ∏(x‚Çú,t) + ‚àöŒ≤‚Çú z
Discrete approximation to continuous Langevin

SDE Limit:
As T ‚Üí ‚àû, Œ≤‚Çú ‚Üí 0, Œ≤‚ÇúT ‚Üí constant:
DDPM approaches continuous SDE
dx = -¬ΩŒ≤(t)x dt + ‚àöŒ≤(t) dW
```

**Training Objective Equivalence**:
```
Score Matching Loss:
J_SM = E_t[Œª(t)E_{x‚ÇÄ,Œµ}[||s_Œ∏(x‚Çú,t) - ‚àálog q(x‚Çú|x‚ÇÄ)||¬≤]]

DDPM Loss:
L_DDPM = E_t,x‚ÇÄ,Œµ[||Œµ - Œµ_Œ∏(x‚Çú,t)||¬≤]

Equivalence:
‚àálog q(x‚Çú|x‚ÇÄ) = -Œµ/‚àö(1-·æ±‚Çú)
Therefore: s_Œ∏ = -Œµ_Œ∏/‚àö(1-·æ±‚Çú)
DDPM loss ‚â° score matching with Œª(t) = (1-·æ±‚Çú)

Weight Function:
Œª(t) = (1-·æ±‚Çú) gives more weight to low noise
Balances different timesteps
Can be modified for different emphasis
```

### Advanced Theoretical Analysis

#### Information-Theoretic Perspective
**Rate-Distortion Analysis**:
```
Forward Process as Encoder:
Encoder: x‚ÇÄ ‚Üí x‚ÇÅ:T (adds noise)
Rate: I(x‚ÇÄ; x‚ÇÅ:T) (information preserved)
Distortion: E[||x‚ÇÄ - xÃÇ‚ÇÄ||¬≤] (reconstruction error)

Reverse Process as Decoder:
Decoder: x‚ÇÅ:T ‚Üí xÃÇ‚ÇÄ (removes noise)
Optimal decoder minimizes distortion given rate
DDPM approximates optimal decoder

Rate-Distortion Curve:
R(D) = min I(x‚ÇÄ; x‚ÇÅ:T) subject to E[||x‚ÇÄ - xÃÇ‚ÇÄ||¬≤] ‚â§ D
DDPM operates on this curve
Different noise schedules give different operating points

Information Bottleneck:
Forward process creates information bottleneck
Reverse process recovers information
Similar to VAE but with hierarchical structure
```

**Generalization Bounds**:
```
Sample Complexity:
Number of samples needed for accurate density modeling
Depends on data distribution complexity
DDPM may have better sample complexity than GANs

Approximation Error:
Neural network approximation quality
Universal approximation theorems apply
Depth and width requirements for accuracy

Generalization Error:
Test vs training performance gap
Depends on model complexity and sample size
DDPM training objective may provide implicit regularization

Convergence Guarantees:
Under appropriate conditions:
Generated distribution approaches data distribution
Rate depends on approximation quality and schedule choice
```

---

## üéØ Advanced Understanding Questions

### DDPM Mathematical Theory:
1. **Q**: Analyze the mathematical relationship between the DDPM variational lower bound and the simplified training objective, deriving conditions under which they are equivalent.
   **A**: Mathematical relationship: VLB = Œ£‚Çú L‚Çú where L‚Çú are KL divergences between forward posterior and reverse model. Simplified objective: E[||Œµ - Œµ_Œ∏||¬≤] ignores weighting and constants. Equivalence conditions: (1) optimal variance schedule œÉ‚Çú¬≤ = Œ≤ÃÉ‚Çú, (2) specific weighting Œª(t) = (1-·æ±‚Çú), (3) small step size approximation. Analysis: simplified objective corresponds to weighted VLB with emphasis on low-noise timesteps. Deviation from VLB: ignores prior matching term L_T, uses uniform weighting across timesteps. Practical implication: simplified objective often works better despite theoretical suboptimality, suggesting VLB may not be tight bound for finite T.

2. **Q**: Develop a theoretical framework for analyzing the impact of different noise schedules on DDPM training dynamics and generation quality.
   **A**: Framework components: (1) signal-to-noise ratio evolution SNR(t) = ·æ±‚Çú/(1-·æ±‚Çú), (2) information preservation I(x‚ÇÄ; x‚Çú), (3) score estimation difficulty. Mathematical analysis: linear schedule gives uniform information removal, cosine schedule preserves structure longer. Training dynamics: early timesteps (high noise) easier to learn, late timesteps (low noise) require fine details. Generation quality: smooth SNR transitions prevent artifacts, sufficient noise ensures mode coverage. Optimal schedules: balance information preservation with computational efficiency. Theoretical insight: schedule should match data complexity - complex structures need slower noise addition, simple patterns can handle faster schedules.

3. **Q**: Compare the mathematical foundations of DDPM and score-based diffusion models, analyzing their theoretical equivalence and practical differences.
   **A**: Mathematical equivalence: DDPM predicts noise Œµ_Œ∏, score models predict score s_Œ∏ = -Œµ_Œ∏/‚àö(1-·æ±‚Çú). Both minimize same objective up to weighting function Œª(t). Training objectives equivalent when Œª(t) = (1-·æ±‚Çú). Practical differences: DDPM uses fixed timesteps, score models often continuous time. DDPM emphasizes low-noise regions, score models can weight differently. Implementation: DDPM more structured (discrete steps), score models more flexible (adaptive sampling). Convergence: both converge to same distribution under appropriate conditions. Theoretical insight: choice between formulations affects optimization dynamics and implementation convenience but not fundamental capabilities.

### Noise Schedule Theory:
4. **Q**: Analyze the mathematical principles behind optimal noise schedule design, deriving theoretical bounds on information preservation and generation quality.
   **A**: Optimal schedule principles: balance information preservation with exploration capability. Mathematical framework: I(x‚ÇÄ; x‚Çú) = H(x‚ÇÄ) - H(Œµ)/2 log(2œÄe(1-·æ±‚Çú)) for Gaussian case. Information bound: I(x‚ÇÄ; x‚Çú) ‚â• 0 with equality when x‚Çú ~ N(0,I). Generation quality: depends on score estimation accuracy across noise levels. Theoretical bounds: reconstruction error ‚â§ Œ£‚Çú approximation_error(t) √ó information_weight(t). Optimal schedules: minimize total error subject to computational constraints. Design principles: slower noise addition for complex structures, ensure sufficient exploration, smooth transitions between scales. Key insight: no universally optimal schedule, must adapt to data characteristics and computational budget.

5. **Q**: Develop a mathematical theory for the approximation quality of the Gaussian assumption in DDPM reverse transitions, analyzing when this assumption holds and fails.
   **A**: Gaussian assumption: p_Œ∏(x‚Çú‚Çã‚ÇÅ|x‚Çú) = N(Œº_Œ∏, œÉ‚Çú¬≤I). Validity conditions: (1) small step size Œ≤‚Çú, (2) smooth data distribution, (3) sufficient diffusion time. Mathematical analysis: central limit theorem suggests Gaussianity for small steps, but mode-splitting can occur. Failure modes: multimodal posteriors when step size too large, non-Gaussian tails for heavy-tailed data, discrete data structures. Approximation quality: KL divergence between true posterior and Gaussian approximation. Theoretical bounds: error O(Œ≤‚Çú¬≤) for smooth distributions under small step assumption. Practical implications: smaller steps improve accuracy but increase computational cost, alternative distributions (mixtures, flows) can improve approximation for complex cases.

6. **Q**: Compare the information-theoretic properties of different DDPM parameterizations (noise prediction, mean prediction, data prediction) and their impact on training dynamics.
   **A**: Information-theoretic comparison: all parameterizations equivalent in terms of mutual information but differ in optimization landscape. Noise prediction: Œµ_Œ∏ directly predicts corruption, simple gradient structure. Mean prediction: Œº_Œ∏ predicts reverse mean, requires careful scaling. Data prediction: xÃÇ‚ÇÄ_Œ∏ predicts clean data, interpretable but potentially unstable. Training dynamics: noise prediction often most stable due to consistent scale across timesteps. Gradient analysis: different parameterizations have different sensitivity to approximation errors. Numerical stability: noise prediction less sensitive to extreme values, data prediction can amplify errors. Theoretical insight: parameterization choice affects optimization efficiency and numerical stability but not fundamental model capacity or asymptotic performance.

### Advanced Applications:
7. **Q**: Design a mathematical framework for analyzing the sample complexity and generalization bounds of DDPM across different data distributions and model architectures.
   **A**: Framework components: (1) data distribution complexity (smoothness, support size), (2) neural network approximation capacity, (3) finite sample effects. Sample complexity: depends on effective dimension of data distribution and score function complexity class. Mathematical bounds: O(d_eff/Œµ¬≤) samples for Œµ-accurate generation under smoothness assumptions. Architecture impact: deeper networks better for complex distributions but require more samples. Generalization analysis: uniform convergence over score function class, depends on Rademacher complexity. Data-dependent bounds: smoother distributions require fewer samples, multimodal distributions increase complexity. Theoretical guarantee: under appropriate regularity conditions, DDPM achieves minimax optimal sample complexity for density estimation. Key insight: sample complexity scales with intrinsic rather than ambient dimension when data has low-dimensional structure.

8. **Q**: Develop a unified mathematical theory connecting DDPM to other generative models (VAEs, GANs, flows), identifying fundamental relationships and trade-offs.
   **A**: Unified framework: all generative models minimize divergences between data and model distributions but use different metrics and optimization strategies. DDPM minimizes weighted score matching objective (Fisher divergence variant). VAEs minimize reverse KL divergence via ELBO. GANs minimize JS divergence via adversarial training. Flows minimize forward KL via change of variables. Mathematical connections: all relate to optimal transport in different metrics, DDPM can be viewed as hierarchical VAE with specific encoder structure. Trade-offs: DDPM (stable training, slow sampling), VAEs (fast sampling, blurry images), GANs (sharp images, unstable training), flows (exact likelihood, architectural constraints). Fundamental relationships: choice of divergence determines model properties, optimization method affects training dynamics. Theoretical insight: no single model dominates all scenarios, choice should match application requirements and constraints.

---

## üîë Key DDPM Theory Principles

1. **Hierarchical Diffusion**: DDPM uses a hierarchical approach with many small noise steps, enabling stable training and high-quality generation through gradual structure removal and reconstruction.

2. **Variational Foundation**: Despite using simplified training objectives, DDPM has principled probabilistic foundations through variational lower bound optimization of the evidence.

3. **Score-Based Equivalence**: DDPM is mathematically equivalent to score-based diffusion models, with different parameterizations affecting optimization dynamics but not fundamental capabilities.

4. **Information-Theoretic Design**: Noise schedules should be designed based on information-theoretic principles, balancing structure preservation with sufficient exploration for mode coverage.

5. **Gaussian Approximation**: The Gaussian assumption for reverse transitions is reasonable for small steps but can be limiting for complex distributions, suggesting potential improvements through more flexible transition models.

---

**Next**: Continue with Day 5 - Implementing DDPM from Scratch Theory