# Day 6 - Part 3: Classical Computer Vision Techniques and Mathematical Analysis

## üìö Learning Objectives
By the end of this section, you will understand:
- Image segmentation algorithms and their mathematical foundations
- Template matching theory and correlation-based methods
- Object detection and recognition using classical approaches
- Geometric transformations and image registration techniques
- Stereo vision and 3D reconstruction mathematical principles
- Optical flow computation and motion analysis theory

---

## üéØ Image Segmentation Theory

### Region-Based Segmentation

#### Region Growing Algorithms
**Mathematical Foundation**:
```
Region Growing Process:
R = {(x,y) : |I(x,y) - Œº_R| < T}

Where:
- R: Current region
- Œº_R: Region mean intensity
- T: Threshold parameter
- I(x,y): Image intensity at (x,y)

Adaptive Threshold:
T(x,y) = k √ó œÉ_local(x,y)
where œÉ_local is local standard deviation

Connectivity Criteria:
4-connectivity: N‚ÇÑ = {(x¬±1,y), (x,y¬±1)}
8-connectivity: N‚Çà = N‚ÇÑ ‚à™ {(x¬±1,y¬±1)}

Homogeneity Predicate:
P(R) = true if Var(R) < threshold
Complex predicates can include:
- Mean intensity difference
- Texture measures
- Color similarity
```

**Split-and-Merge Algorithm**:
```
Quadtree Representation:
Recursive subdivision into 4 quadrants
Each node represents image region

Split Criterion:
Split region R if P(R) = false
where P is homogeneity predicate

Merge Criterion:
Merge adjacent regions R·µ¢, R‚±º if P(R·µ¢ ‚à™ R‚±º) = true

Algorithm:
1. Start with entire image
2. Split inhomogeneous regions
3. Merge similar adjacent regions
4. Repeat until convergence

Mathematical Properties:
- Convergence guaranteed for monotonic predicates
- Final segmentation depends on split/merge order
- Computational complexity: O(n log n)
```

#### Watershed Segmentation
**Mathematical Morphology Foundation**:
```
Topographic Interpretation:
I(x,y) = altitude at position (x,y)
Watershed = drainage divide between catchment basins

Gradient-Based Approach:
W(x,y) = ||‚àáI(x,y)||
Use gradient magnitude as topographic surface

Watershed Algorithm:
1. Find regional minima (markers)
2. Simulate flooding from markers
3. Build dams where watersheds meet
4. Result: Segmented regions

Mathematical Definition:
Watershed of function f:
WS(f) = {x : ‚àÄŒµ>0, ‚àÉ distinct minima m·µ¢,m‚±º 
         such that B(x,Œµ) intersects watersheds to both m·µ¢,m‚±º}
```

**Marker-Controlled Watershed**:
```
Over-segmentation Problem:
Pure watershed often produces too many regions
Solution: Use markers to control segmentation

Marker Selection:
Internal markers: Object seeds (local minima)
External markers: Background seeds

Modified Gradient:
G'(x,y) = {0 if (x,y) ‚àà markers
          {G(x,y) otherwise

Advantages:
- Reduces over-segmentation
- Incorporates prior knowledge
- Controllable segmentation granularity

Mathematical Properties:
- Markers impose topological constraints
- Results in connected regions
- Computational complexity: O(n log n)
```

### Edge-Based Segmentation

#### Active Contours (Snakes)
**Energy Functional**:
```
Snake Energy:
E = ‚à´‚ÇÄ¬π [E‚Çë‚Çô‚Çú(v(s)) + E·µ¢‚Çò‚Çê(v(s)) + E‚Çë‚Çí‚Çô(v(s))] ds

Where v(s) = (x(s), y(s)) is parametric contour

Internal Energy (Smoothness):
E‚Çë‚Çô‚Çú = ¬Ω[Œ±(s)|v'(s)|¬≤ + Œ≤(s)|v''(s)|¬≤]
- Œ±(s): Tension (first derivative term)
- Œ≤(s): Rigidity (second derivative term)

Image Energy (Data Term):
E·µ¢‚Çò‚Çê = -Œ≥|‚àáI(v(s))|¬≤
Attracts snake to edges

External Energy (Constraints):
E‚Çë‚Çí‚Çô: User-defined constraints (points, lines)

Euler-Lagrange Equation:
Œ±v''(s) - Œ≤v''''(s) - ‚àáE‚Çë‚Çì‚Çú = 0
```

**Geometric Active Contours (Level Sets)**:
```
Level Set Representation:
C = {(x,y) : œÜ(x,y) = 0}
Contour as zero level set of function œÜ

Evolution Equation:
‚àÇœÜ/‚àÇt = F|‚àáœÜ|

Where F = speed function:
F = (1 - Œµ¬∑Œ∫) + ŒΩ¬∑g(I)

Terms:
- Œ∫: Curvature (smoothness)
- g(I): Image-dependent stopping function
- Œµ, ŒΩ: Weighting parameters

Advantages:
- Handles topology changes naturally
- No parametrization required
- Stable numerical implementation

Chan-Vese Model:
Energy functional based on region statistics
Minimizes variance within regions
Handles images without clear edges
```

### Clustering-Based Segmentation

#### K-Means Clustering
**Mathematical Formulation**:
```
Objective Function:
J = Œ£·µ¢‚Çå‚ÇÅ‚Åø Œ£‚±º‚Çå‚ÇÅ·µè w·µ¢‚±º ||x·µ¢ - Œº‚±º||¬≤

Where:
- w·µ¢‚±º = 1 if point i assigned to cluster j, 0 otherwise
- Œº‚±º: Centroid of cluster j
- k: Number of clusters

K-Means Algorithm:
1. Initialize k centroids randomly
2. Assign points to nearest centroid
3. Update centroids: Œº‚±º = (1/n‚±º) Œ£·µ¢‚ààC‚±º x·µ¢
4. Repeat until convergence

Convergence Properties:
- Objective function decreases monotonically
- Guaranteed to converge to local minimum
- Result depends on initialization

Feature Vectors for Images:
- Intensity: x = [I(x,y)]
- Color: x = [R(x,y), G(x,y), B(x,y)]
- Texture: x = [I(x,y), texture_features]
- Spatial: x = [I(x,y), x, y]
```

#### Mean Shift Clustering
**Mathematical Theory**:
```
Kernel Density Estimation:
f(x) = (1/n) Œ£·µ¢‚Çå‚ÇÅ‚Åø K((x - x·µ¢)/h)

Mean Shift Vector:
m(x) = [Œ£·µ¢ x·µ¢ g(||x - x·µ¢||¬≤/h¬≤)] / [Œ£·µ¢ g(||x - x·µ¢||¬≤/h¬≤)] - x

Where g(x) = -K'(x) (derivative of kernel)

Gaussian Kernel:
K(x) = exp(-¬Ω||x||¬≤)
g(x) = exp(-¬Ω||x||¬≤)

Mean Shift Algorithm:
1. For each point, compute mean shift vector
2. Shift point by mean shift vector
3. Repeat until convergence
4. Points converging to same mode form cluster

Properties:
- Non-parametric (no assumption on cluster number)
- Finds modes of density function
- Robust to outliers
- Bandwidth h controls cluster granularity
```

**Application to Image Segmentation**:
```
Feature Space:
Combine spatial and color information:
x = [r, g, b, x, y]

Bandwidth Selection:
- Spatial bandwidth: h‚Çõ
- Color bandwidth: h·µ£
- Controls segmentation granularity

Joint Domain:
Distance metric: d¬≤ = ||x‚Çõ - y‚Çõ||¬≤/h‚Çõ¬≤ + ||x·µ£ - y·µ£||¬≤/h·µ£¬≤

Advantages:
- Preserves spatial connectivity
- Handles irregular cluster shapes
- No need to specify cluster number
- Robust segmentation results
```

---

## üìê Template Matching and Correlation

### Cross-Correlation Theory

#### Normalized Cross-Correlation (NCC)
**Mathematical Definition**:
```
Cross-Correlation:
C(u,v) = Œ£‚Çì Œ£·µß I(x,y) √ó T(x-u, y-v)

Normalized Cross-Correlation:
NCC(u,v) = Œ£‚Çì Œ£·µß [I(x,y) - ƒ™][T(x-u,y-v) - TÃÑ] / 
           ‚àö(Œ£‚Çì Œ£·µß [I(x,y) - ƒ™]¬≤ √ó Œ£‚Çì Œ£·µß [T(x-u,y-v) - TÃÑ]¬≤)

Where:
- I: Image
- T: Template
- ƒ™, TÃÑ: Mean values
- (u,v): Template position

Properties:
- NCC ‚àà [-1, 1]
- NCC = 1: Perfect match
- NCC = -1: Perfect negative match
- NCC = 0: No correlation
```

**Fast Computation**:
```
FFT-Based Correlation:
C = IFFT(FFT(I) √ó FFT*(T))
where * denotes complex conjugate

Computational Complexity:
Direct: O(MN √ó mn) for M√óN image, m√ón template
FFT: O(MN log(MN))
Speedup significant for large templates

Sliding Window Efficiency:
Use integral images for sum computation
Update correlation incrementally
Especially efficient for rectangular templates
```

#### Phase Correlation
**Mathematical Foundation**:
```
Phase Correlation Function:
R(u,v) = IFFT(F‚ÇÅ(œâ‚ÇÅ,œâ‚ÇÇ) √ó F‚ÇÇ*(œâ‚ÇÅ,œâ‚ÇÇ) / |F‚ÇÅ(œâ‚ÇÅ,œâ‚ÇÇ) √ó F‚ÇÇ*(œâ‚ÇÅ,œâ‚ÇÇ)|)

Where F‚ÇÅ, F‚ÇÇ are FFTs of images I‚ÇÅ, I‚ÇÇ

Translation Estimation:
If I‚ÇÇ(x,y) = I‚ÇÅ(x-x‚ÇÄ, y-y‚ÇÄ) then
R(u,v) = Œ¥(u-x‚ÇÄ, v-y‚ÇÄ)
Peak location gives translation

Advantages:
- Robust to illumination changes
- Subpixel accuracy
- Efficient FFT implementation
- Works for pure translation

Limitations:
- Assumes pure translation
- Sensitive to noise
- Requires similar content
```

### Multi-Scale Template Matching

#### Scale-Invariant Matching
**Pyramid-Based Approach**:
```
Image Pyramid:
I‚ÇÄ = Original image
I‚Çô = Downsample(I‚Çô‚Çã‚ÇÅ) for n = 1,2,...,L

Scale Factor:
Typically 2:1 downsampling ratio
œÉ levels: I_œÉ = Gaussian_blur(I, œÉ) then downsample

Template Pyramid:
Create templates at multiple scales
Match template T‚Çõ with image I‚Çõ at each scale

Coarse-to-Fine Search:
1. Start matching at coarsest level
2. Refine match location at finer levels
3. Propagate and refine estimates

Computational Benefits:
Reduces search space exponentially
Total computation ‚âà 4/3 √ó single-scale cost
```

**Deformable Template Matching**:
```
Affine Template Model:
T'(x,y) = T(ax + by + c, dx + ey + f)
6 parameters: [a,b,c,d,e,f]

Optimization:
Minimize: E = Œ£‚Çì Œ£·µß [I(x,y) - T'(x,y)]¬≤
Use gradient descent or Levenberg-Marquardt

Lucas-Kanade Template Tracking:
Linearize around current estimate
Solve for parameter updates iteratively
Efficient for small deformations

Jacobian Matrix:
J = ‚àÇT/‚àÇp where p = parameter vector
Update: Œîp = (J·µÄJ)‚Åª¬πJ·µÄ[I - T]
```

---

## üéØ Classical Object Detection and Recognition

### Sliding Window Detection

#### Multi-Scale Detection Framework
**Detection Pipeline**:
```
Sliding Window Process:
1. Generate windows at multiple scales
2. Extract features from each window
3. Classify window (object vs. background)
4. Apply non-maximum suppression

Scale Generation:
S‚Çô = S‚ÇÄ √ó r‚Åø where r = scale ratio
Common: r = 1.2 (20% scale increase)

Window Density:
Step size: s pixels
Total windows ‚âà (W√óH√óS) / s¬≤
where W√óH = image size, S = number of scales

Classification:
Binary classifier: f(x) ‚Üí {-1, +1}
Confidence score: P(object | features)
```

**Non-Maximum Suppression (NMS)**:
```
Overlap Computation:
IoU = Area(bbox‚ÇÅ ‚à© bbox‚ÇÇ) / Area(bbox‚ÇÅ ‚à™ bbox‚ÇÇ)

NMS Algorithm:
1. Sort detections by confidence score
2. Select highest scoring detection
3. Remove overlapping detections (IoU > threshold)
4. Repeat with remaining detections

Soft NMS:
Instead of removing, reduce confidence:
s·µ¢ = s·µ¢ √ó exp(-IoU¬≤/œÉ¬≤)
Preserves nearby detections with lower confidence

Mathematical Properties:
- Greedy algorithm (may not be globally optimal)
- Threshold selection affects precision/recall trade-off
- Computational complexity: O(n¬≤)
```

#### Viola-Jones Face Detection
**Haar Feature Theory**:
```
Haar-like Features:
Two-rectangle: Œ£ white - Œ£ black
Three-rectangle: Œ£ outer - 2√óŒ£ middle
Four-rectangle: Œ£ diagonal_opposite

Integral Image:
II(x,y) = Œ£·µ¢‚â§‚Çì Œ£‚±º‚â§·µß I(i,j)

Fast Rectangle Sum:
Sum(x‚ÇÅ,y‚ÇÅ,x‚ÇÇ,y‚ÇÇ) = II(x‚ÇÇ,y‚ÇÇ) - II(x‚ÇÅ-1,y‚ÇÇ) - II(x‚ÇÇ,y‚ÇÅ-1) + II(x‚ÇÅ-1,y‚ÇÅ-1)

Feature Computation:
Any rectangular sum in O(1) time
Enables real-time feature extraction
Large feature pool: >100,000 features for 24√ó24 window
```

**AdaBoost Training**:
```
Weak Classifier:
h‚±º(x) = {1 if p‚±ºf‚±º(x) < p‚±ºŒ∏‚±º
        {0 otherwise

Where:
- f‚±º: feature value
- Œ∏‚±º: threshold
- p‚±º: polarity (¬±1)

AdaBoost Algorithm:
1. Initialize weights: w·µ¢ = 1/(2m), 1/(2l)
2. For t = 1,...,T:
   a. Train weak classifier h‚Çú
   b. Choose h‚Çú with minimum weighted error
   c. Update weights based on classification results
3. Final classifier: H(x) = sign(Œ£‚Çú Œ±‚Çúh‚Çú(x))

Weight Update:
w·µ¢ = w·µ¢ √ó exp(-Œ±‚Çúy·µ¢h‚Çú(x·µ¢))
where Œ±‚Çú = ¬Ωln((1-Œµ‚Çú)/Œµ‚Çú)
```

**Cascade Architecture**:
```
Cascade Design:
Series of classifiers with increasing complexity
Early stages: Simple, fast (eliminate easy negatives)
Later stages: Complex, accurate (refine decisions)

Rejection Cascade:
Stage 1: If H‚ÇÅ(x) < Œ∏‚ÇÅ, reject (background)
Stage 2: If H‚ÇÇ(x) < Œ∏‚ÇÇ, reject
...
Stage n: Final decision

Detection Rate:
D = ‚àè·µ¢ d·µ¢ (product of individual stage detection rates)

False Positive Rate:
F = ‚àè·µ¢ f·µ¢ (product of individual stage false positive rates)

Training Strategy:
Set target performance for each stage
Train to achieve desired d and f values
Adjust thresholds for optimal cascade performance
```

### Bag-of-Words (BoW) Model

#### Visual Vocabulary Construction
**Clustering for Vocabulary**:
```
Feature Extraction:
1. Detect keypoints in training images
2. Extract local descriptors (SIFT, SURF, etc.)
3. Collect large descriptor dataset

K-Means Clustering:
Minimize: J = Œ£·µ¢‚Çå‚ÇÅ‚Åø ||x·µ¢ - Œº‚Çí‚Çç·µ¢‚Çé||¬≤
where o(i) = assigned cluster for descriptor i

Vocabulary Size:
Typical: k = 1000-10000 visual words
Trade-off: Small k (underfitting), Large k (overfitting)

Alternative Clustering:
- Hierarchical k-means (vocabulary trees)
- Gaussian Mixture Models
- Online learning approaches
```

**Spatial Pyramid Matching**:
```
Pyramid Levels:
Level 0: Entire image (1 region)
Level 1: 2√ó2 grid (4 regions)
Level 2: 4√ó4 grid (16 regions)

Histogram Computation:
H^l_i = histogram of visual words in region i at level l

Intersection Kernel:
K(H^l, G^l) = Œ£·µ¢ min(H^l_i, G^l_i)

Weighted Combination:
K = Œ£‚Çó w‚Çó √ó K(H^l, G^l)
where w‚Çó = 1/2^(L-l) (higher weight for finer levels)

Properties:
- Captures spatial layout information
- Maintains computational efficiency
- Provides multi-scale spatial representation
```

#### Classification and Retrieval
**SVM Classification**:
```
Linear SVM:
Minimize: ¬Ω||w||¬≤ + C Œ£·µ¢ Œæ·µ¢
Subject to: y·µ¢(w·µÄx·µ¢ + b) ‚â• 1 - Œæ·µ¢, Œæ·µ¢ ‚â• 0

Histogram Intersection Kernel:
K(h,g) = Œ£·µ¢ min(h·µ¢, g·µ¢)

Chi-Square Kernel:
K(h,g) = exp(-Œ≥ Œ£·µ¢ (h·µ¢ - g·µ¢)¬≤/(h·µ¢ + g·µ¢))

Multi-class Classification:
One-vs-all: Train binary classifier for each class
One-vs-one: Train classifier for each class pair
Error-correcting codes: Robust multi-class approach
```

**Image Retrieval**:
```
Similarity Measures:
Euclidean: d(h,g) = ||h - g||‚ÇÇ
Cosine: sim(h,g) = h·µÄg/(||h|| ||g||)
Histogram intersection: sim(h,g) = Œ£·µ¢ min(h·µ¢,g·µ¢)

TF-IDF Weighting:
Term Frequency: tf(w,d) = frequency of word w in document d
Inverse Document Frequency: idf(w) = log(N/df(w))
Weight: w = tf √ó idf

Inverted Index:
For each visual word, maintain list of images containing it
Enables efficient retrieval for large databases
Query processing: Intersect posting lists
```

---

## üìè Geometric Transformations and Registration

### 2D Transformations

#### Homogeneous Coordinates
**Transformation Matrices**:
```
Homogeneous Representation:
[x'] = [a b c] [x]
[y']   [d e f] [y]
[1 ]   [0 0 1] [1]

Translation:
T = [1 0 t‚Çì]
    [0 1 t·µß]
    [0 0 1 ]

Rotation:
R = [cos Œ∏  -sin Œ∏  0]
    [sin Œ∏   cos Œ∏  0]
    [0       0      1]

Scaling:
S = [s‚Çì  0   0]
    [0   s·µß  0]
    [0   0   1]

Composite Transform:
M = T √ó R √ó S (order matters!)
```

**Affine Transformations**:
```
General Affine:
[x'] = [a b] [x] + [t‚Çì]
[y']   [c d] [y]   [t·µß]

Properties:
- Preserves parallelism
- Preserves ratios of parallel lengths
- Maps lines to lines
- 6 degrees of freedom

Parameter Estimation:
Minimum 3 point correspondences
Linear system: Ax = b
Least squares solution: x = (A·µÄA)‚Åª¬πA·µÄb

Decomposition:
A = R √ó S √ó H
where R = rotation, S = scaling, H = shear
```

#### Perspective Transformations
**Homography Estimation**:
```
Perspective Transformation:
[x'] = [h‚ÇÅ‚ÇÅ h‚ÇÅ‚ÇÇ h‚ÇÅ‚ÇÉ] [x]
[y']   [h‚ÇÇ‚ÇÅ h‚ÇÇ‚ÇÇ h‚ÇÇ‚ÇÉ] [y]
[w ]   [h‚ÇÉ‚ÇÅ h‚ÇÉ‚ÇÇ h‚ÇÉ‚ÇÉ] [1]

x' = (h‚ÇÅ‚ÇÅx + h‚ÇÅ‚ÇÇy + h‚ÇÅ‚ÇÉ)/(h‚ÇÉ‚ÇÅx + h‚ÇÉ‚ÇÇy + h‚ÇÉ‚ÇÉ)
y' = (h‚ÇÇ‚ÇÅx + h‚ÇÇ‚ÇÇy + h‚ÇÇ‚ÇÉ)/(h‚ÇÉ‚ÇÅx + h‚ÇÉ‚ÇÇy + h‚ÇÉ‚ÇÉ)

Direct Linear Transform (DLT):
Linearize: x·µ¢'(h‚ÇÉ‚ÇÅx·µ¢ + h‚ÇÉ‚ÇÇy·µ¢ + h‚ÇÉ‚ÇÉ) = h‚ÇÅ‚ÇÅx·µ¢ + h‚ÇÅ‚ÇÇy·µ¢ + h‚ÇÅ‚ÇÉ
          y·µ¢'(h‚ÇÉ‚ÇÅx·µ¢ + h‚ÇÉ‚ÇÇy·µ¢ + h‚ÇÉ‚ÇÉ) = h‚ÇÇ‚ÇÅx·µ¢ + h‚ÇÇ‚ÇÇy·µ¢ + h‚ÇÇ‚ÇÉ

Matrix Form: Ah = 0
SVD Solution: h = V_min (smallest singular vector)
Minimum: 4 point correspondences
```

**Robust Estimation**:
```
RANSAC for Homography:
1. Sample 4 point pairs randomly
2. Compute homography H
3. Count inliers: ||H¬∑x·µ¢ - x'·µ¢|| < threshold
4. Repeat N iterations
5. Select H with most inliers

Refinement:
Use all inliers for final estimation
Non-linear optimization (Levenberg-Marquardt)
Minimize reprojection error: Œ£·µ¢ ||H¬∑x·µ¢ - x'·µ¢||¬≤

Degeneracy Cases:
- Collinear points: Infinite solutions
- Points on conic: Unstable estimation
- Planar scene: Reduced constraints
Detection and handling of degenerate configurations
```

### Image Registration

#### Feature-Based Registration
**Registration Pipeline**:
```
1. Feature Detection:
   Extract keypoints in both images
   Common detectors: SIFT, SURF, ORB

2. Feature Matching:
   Compute descriptor similarities
   Apply ratio test and cross-check

3. Transformation Estimation:
   Use RANSAC for robust estimation
   Model: Affine, homography, or similarity

4. Image Warping:
   Apply transformation to align images
   Interpolation for sub-pixel accuracy

Evaluation Metrics:
- Registration accuracy: RMS error
- Robustness: Success rate
- Efficiency: Computational time
```

**Intensity-Based Registration**:
```
Similarity Measures:
Sum of Squared Differences (SSD):
SSD = Œ£‚Çì,·µß [I‚ÇÅ(x,y) - I‚ÇÇ(x,y)]¬≤

Normalized Cross Correlation (NCC):
NCC = Œ£‚Çì,·µß [I‚ÇÅ(x,y) - Œº‚ÇÅ][I‚ÇÇ(x,y) - Œº‚ÇÇ] / (œÉ‚ÇÅœÉ‚ÇÇN)

Mutual Information (MI):
MI = Œ£·µ¢,‚±º p(i,j) log(p(i,j)/(p·µ¢(i)p‚±º(j)))

Optimization:
Gradient descent on similarity function
Powell's method for derivative-free optimization
Multi-resolution for global optimization
```

#### Non-Rigid Registration
**Thin Plate Splines (TPS)**:
```
TPS Interpolation:
f(x,y) = a‚ÇÅ + a‚ÇÇx + a‚ÇÉy + Œ£·µ¢ w·µ¢ U(||(x,y) - (x·µ¢,y·µ¢)||)

Where U(r) = r¬≤ log r (radial basis function)

Constraints:
Œ£·µ¢ w·µ¢ = 0
Œ£·µ¢ w·µ¢x·µ¢ = 0
Œ£·µ¢ w·µ¢y·µ¢ = 0

Bending Energy:
E = ‚à´‚à´ [(‚àÇ¬≤f/‚àÇx¬≤)¬≤ + 2(‚àÇ¬≤f/‚àÇx‚àÇy)¬≤ + (‚àÇ¬≤f/‚àÇy¬≤)¬≤] dx dy

Regularized Solution:
Minimize: Œ£·µ¢ ||f(x·µ¢,y·µ¢) - y·µ¢||¬≤ + ŒªE
Œª controls smoothness vs. fitting accuracy
```

**Optical Flow Registration**:
```
Lucas-Kanade Method:
Assume: I(x,y,t) = I(x+dx,y+dy,t+dt)

Brightness Constancy:
‚àÇI/‚àÇx ¬∑ dx/dt + ‚àÇI/‚àÇy ¬∑ dy/dt + ‚àÇI/‚àÇt = 0

Optical Flow Equation:
I‚Çìu + I·µßv + I‚Çú = 0
where u = dx/dt, v = dy/dt

Local Solution:
Assume constant flow in neighborhood
Least squares: [u v]·µÄ = -(A·µÄA)‚Åª¬πA·µÄb

Pyramid Implementation:
Coarse-to-fine estimation
Handle large displacements
Iterative refinement
```

---

## üëÅÔ∏è Stereo Vision and 3D Reconstruction

### Epipolar Geometry

#### Fundamental Matrix
**Mathematical Foundation**:
```
Epipolar Constraint:
x'·µÄFx = 0

Where:
- x, x': Corresponding points in homogeneous coordinates
- F: Fundamental matrix (3√ó3)

Geometric Interpretation:
- Fx: Epipolar line in second image
- F·µÄx': Epipolar line in first image
- e, e': Epipoles (Fe = 0, F·µÄe' = 0)

Properties:
- rank(F) = 2 (singular matrix)
- 7 degrees of freedom
- Skew-symmetric part encodes epipolar geometry

Eight-Point Algorithm:
Linear system: Af = 0
where A constructed from point correspondences
SVD solution with rank-2 constraint enforcement
```

**Essential Matrix**:
```
Calibrated Cameras:
E = K'·µÄFK

Where K, K' are camera calibration matrices

Essential Matrix Properties:
E = [t]‚ÇìR
where [t]‚Çì is skew-symmetric matrix, R is rotation

Constraints:
- 2EE·µÄE - trace(EE·µÄ)E = 0
- det(E) = 0
- 5 degrees of freedom

Five-Point Algorithm:
Minimal solver for essential matrix
Handles calibrated camera case
More stable than fundamental matrix estimation
```

#### Stereo Rectification
**Rectification Process**:
```
Goal: Transform images so epipolar lines are horizontal

Rectification Matrices:
H‚ÇÅ, H‚ÇÇ such that:
- F_rect = [0 0 0; 0 0 -1; 0 1 0]
- Epipolar lines become horizontal
- Minimize image distortion

Algorithm:
1. Compute fundamental matrix F
2. Find epipoles e, e'
3. Construct rectification homographies
4. Warp images to canonical form

Uncalibrated Rectification:
Use projective transformations
Preserve cross-ratios
Enable stereo matching without calibration

Quality Metrics:
- Epipolar line alignment error
- Image distortion measures
- Preserved image content
```

#### Dense Stereo Matching
**Disparity Computation**:
```
Disparity Definition:
d(x,y) = x_left - x_right
For rectified stereo pair

Window-Based Matching:
C(x,y,d) = Œ£·µ¢,‚±º [I_L(x+i,y+j) - I_R(x+i-d,y+j)]¬≤

Winner-Take-All (WTA):
d*(x,y) = argmin_d C(x,y,d)

Dynamic Programming:
1D optimization along epipolar lines
Smoothness constraints
Occlusion handling

Global Optimization:
Energy minimization:
E = Œ£‚Çö C(p,d‚Çö) + Œ£‚Çö,q V(d‚Çö,dq)
Data term + smoothness term
Graph cuts, belief propagation solutions
```

**3D Reconstruction**:
```
Triangulation:
Given disparity d, compute depth:
Z = (f √ó B) / d
where f = focal length, B = baseline

3D Point:
X = (x √ó Z) / f
Y = (y √ó Z) / f
Z = (f √ó B) / d

Uncertainty Analysis:
œÉ_Z = (Z¬≤/fB) √ó œÉ_d
Depth uncertainty grows quadratically with distance
Larger baseline B improves depth accuracy

Point Cloud Generation:
Convert disparity map to 3D points
Filter outliers and invalid disparities
Apply color information from reference image
```

---

## üåä Optical Flow and Motion Analysis

### Dense Optical Flow

#### Horn-Schunck Method
**Global Smoothness Approach**:
```
Energy Functional:
E = ‚à´‚à´ [(I‚Çìu + I·µßv + I‚Çú)¬≤ + Œ±¬≤(||‚àáu||¬≤ + ||‚àáv||¬≤)] dx dy

Where:
- First term: Brightness constancy constraint
- Second term: Smoothness regularization
- Œ±: Regularization parameter

Euler-Lagrange Equations:
I‚Çì(I‚Çìu + I·µßv + I‚Çú) - Œ±¬≤‚àá¬≤u = 0
I·µß(I‚Çìu + I·µßv + I‚Çú) - Œ±¬≤‚àá¬≤v = 0

Iterative Solution:
u^(n+1) = ≈´^(n) - I‚Çì[I‚Çì≈´^(n) + I·µßvÃÑ^(n) + I‚Çú]/(Œ±¬≤ + I‚Çì¬≤ + I·µß¬≤)
v^(n+1) = vÃÑ^(n) - I·µß[I‚Çì≈´^(n) + I·µßvÃÑ^(n) + I‚Çú]/(Œ±¬≤ + I‚Çì¬≤ + I·µß¬≤)

where ≈´, vÃÑ are local averages
```

#### Lucas-Kanade Method
**Local Approach**:
```
Assumption: Constant flow in local neighborhood

Matrix Formulation:
[I‚Çì‚ÇÅ I·µß‚ÇÅ] [u] = -[I‚Çú‚ÇÅ]
[I‚Çì‚ÇÇ I·µß‚ÇÇ] [v]    [I‚Çú‚ÇÇ]
[  ‚ãÆ  ‚ãÆ ]        [ ‚ãÆ ]

Least Squares Solution:
[u] = -(A·µÄA)‚Åª¬πA·µÄb
[v]

Where A = [I‚Çì I·µß], b = [I‚Çú]

Solvability Condition:
A·µÄA must be well-conditioned
Eigenvalues Œª‚ÇÅ, Œª‚ÇÇ > threshold
Indicates presence of texture (corners)

Aperture Problem:
Only normal component of flow observable
Parallel edges create rank-deficient system
Need texture in multiple orientations
```

### Feature Tracking

#### KLT Tracker
**Tracking Framework**:
```
Template Tracking:
Minimize: Œ£‚Çì,·µß [I‚ÇÅ(x,y) - I‚ÇÇ(x+dx,y+dy)]¬≤

Newton-Raphson Iteration:
[dx] = [dx‚ÇÄ] - H‚Åª¬π‚àáE
[dy]   [dy‚ÇÄ]

Hessian Matrix:
H = [Œ£ I‚Çì¬≤   Œ£ I‚ÇìI·µß]
    [Œ£ I‚ÇìI·µß  Œ£ I·µß¬≤ ]

Gradient:
‚àáE = [Œ£ I‚ÇìI‚Çú]
     [Œ£ I·µßI‚Çú]

Feature Selection:
Select points with large min(Œª‚ÇÅ, Œª‚ÇÇ)
Ensures trackable features
Avoid aperture problem
```

**Multi-Scale Tracking**:
```
Pyramid Construction:
Level 0: Original image
Level L: Gaussian smoothed and downsampled

Coarse-to-Fine Tracking:
1. Track at coarsest level
2. Propagate estimate to finer level
3. Refine estimate
4. Repeat until finest level

Displacement Propagation:
d_L-1 = 2 √ó d_L (double displacement going down pyramid)

Benefits:
- Handle large displacements
- Improved convergence
- Robust to noise
- Computational efficiency
```

#### Optical Flow Applications
**Motion Segmentation**:
```
Motion Clustering:
Cluster pixels by similar flow vectors
K-means on (u, v) flow components
Segment moving objects from background

Layered Motion:
Model scene as multiple moving layers
Each layer has parametric motion model
EM algorithm for layer assignment and parameter estimation

Dominant Motion Estimation:
RANSAC on flow vectors
Estimate background motion (camera motion)
Segment foreground objects with different motion
```

**3D Motion Estimation**:
```
Structure from Motion:
Estimate camera motion and 3D structure
From optical flow across multiple frames

Ego-Motion Estimation:
Focus of Expansion (FOE):
Point where flow vectors converge
Indicates direction of camera translation

Time-to-Contact:
œÑ = Z/Vz = r/||v(r)||
where r = distance from FOE
Applications: Autonomous navigation, collision avoidance

Rotation vs. Translation:
Pure rotation: Rotational flow field
Pure translation: Radial flow field
General motion: Combination of both
```

---

## üéØ Advanced Understanding Questions

### Segmentation Theory:
1. **Q**: Analyze the mathematical properties of different segmentation algorithms and compare their sensitivity to initialization, noise, and parameter selection.
   **A**: Region growing: sensitive to seed selection and threshold, robust to noise within homogeneous regions. Watershed: sensitive to gradient computation, prone to over-segmentation without markers. Active contours: require good initialization, converge to local minima, sensitive to image gradients. K-means: sensitive to initialization and k selection, assumes spherical clusters. Mean shift: robust to initialization, sensitive to bandwidth selection.

2. **Q**: Derive the mathematical relationship between level set evolution and energy minimization in geometric active contours.
   **A**: Level set evolution ‚àÇœÜ/‚àÇt = F|‚àáœÜ| minimizes energy functional E = ‚à´C ds + ‚à´‚à´Œ© g(I)dA where C is contour, Œ© is interior region. Speed function F derives from Euler-Lagrange equation of energy functional. Geometric flows naturally handle topology changes while minimizing perimeter and region-based terms.

3. **Q**: Compare clustering-based segmentation methods and analyze their theoretical foundations and convergence properties.
   **A**: K-means: minimizes within-cluster variance, guaranteed convergence to local minimum, assumes isotropic clusters. Mean shift: finds modes of density function, converges to stationary points, handles arbitrary cluster shapes. EM: maximizes likelihood under mixture model, proven convergence, incorporates probabilistic uncertainty.

### Template Matching and Object Detection:
4. **Q**: Analyze the mathematical relationship between correlation-based matching and optimal filter theory, and derive conditions for optimal template design.
   **A**: Correlation implements matched filtering under Gaussian noise assumptions. Optimal template maximizes SNR = |Œº‚ÇÅ-Œº‚ÇÇ|¬≤/(œÉ‚ÇÅ¬≤+œÉ‚ÇÇ¬≤) where Œº,œÉ are signal/noise statistics. Template should match expected signal pattern while being orthogonal to noise. For unknown targets, Wiener filtering provides optimal trade-off between signal matching and noise suppression.

5. **Q**: Compare the theoretical properties of different multi-scale detection approaches and analyze their computational and accuracy trade-offs.
   **A**: Pyramid methods: logarithmic scale sampling, efficient computation, may miss intermediate scales. Integral images: exact computation for rectangular features, limited to specific feature types. DFT methods: exact scale analysis, computationally expensive for large ranges. Trade-offs: computational efficiency vs. scale coverage vs. accuracy.

6. **Q**: Derive the mathematical foundations of cascade classifiers and analyze their optimization principles for detection accuracy and speed.
   **A**: Cascade optimizes product of detection rates D = ‚àè·µ¢d·µ¢ and false positive rates F = ‚àè·µ¢f·µ¢. Each stage targets high detection rate (d‚â•0.99) and moderate false positive rate (f‚â§0.5). Overall system achieves exponential false positive reduction while maintaining high detection. Optimization balances per-stage complexity with cascade depth.

### Geometric Transformations and Stereo Vision:
7. **Q**: Analyze the mathematical relationship between epipolar geometry and camera calibration, and derive optimal baseline configurations for stereo reconstruction.
   **A**: Fundamental matrix F encodes epipolar geometry independent of calibration. Essential matrix E = K'·µÄFK incorporates calibration. Optimal baseline: large enough for good depth resolution (Z ‚àù 1/disparity), small enough to maintain correspondence matching. Trade-off between depth accuracy and matching reliability.

8. **Q**: Compare different dense stereo matching algorithms and analyze their accuracy-efficiency trade-offs under various scene conditions.
   **A**: Local methods (block matching): fast computation, sensitive to texture-less regions, limited accuracy near discontinuities. Global methods (graph cuts, belief propagation): higher accuracy, handle occlusions, computationally expensive. Semi-global methods: good accuracy-efficiency balance, suitable for real-time applications. Performance depends on scene texture, depth discontinuities, and occlusions.

---

## üîë Key Classical Computer Vision Principles

1. **Mathematical Foundations**: Classical methods rely on well-established mathematical principles from signal processing, optimization, and geometry.

2. **Geometric Understanding**: Explicit geometric models enable interpretable results and principled parameter selection.

3. **Multi-Scale Analysis**: Many classical techniques benefit from multi-scale approaches for robustness and efficiency.

4. **Robust Estimation**: RANSAC and other robust methods are essential for handling outliers and noise in real-world applications.

5. **Trade-off Analysis**: Understanding accuracy-efficiency trade-offs guides algorithm selection for specific applications and computational constraints.

---

**Next**: Continue with Day 6 - Part 4: Data Augmentation Theory and Statistical Analysis